---
title: "432 Class 15 Slides"
author: "github.com/THOMASELOVE/432-2018"
date: "2018-03-05"
output:
  beamer_presentation:
    theme: "Madrid"
    colortheme: "lily"
    fonttheme: "structurebold"
    fig_caption: FALSE
---

```{r set-options, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(comment=NA)
options(width = 60)
```

## Setup

```{r, warning = FALSE, message = FALSE}
library(skimr); library(MASS)
library(robustbase); library(quantreg)
library(lmtest); library(sandwich)
library(boot); library(broom)
library(rms)
library(tidyverse)

decim <- function(x, k) format(round(x, k), nsmall=k)
```

## Today's Materials

0. Comments on Quiz 1
1. Robust Linear Regression Methods with Huber weights
2. Robust Linear Regression with bisquare weights (biweights)
3. Bounded Influence Regression & Least Trimmed Squares
4. Penalized Least Squares using `ols` in the `rms` package
5. Quantile Regression on the Median

- Looking forward to Thursday

# Project 1 Groups

## Project 1 Groups for Discussion in Class on Thursday

Group | Names
------: | -----------------------------------------------------------------------------
1 | Laura Baldassari, Jenny Feng, Maher Kazimi, Satyakam Mishra, Vinh Trinh
2 | Zainab (Albar) Albar, Dongze (Zaza) He, Nik Krieger, Andrew Shan
3 | Andrew Tang, Sneha Vakamudi, Ruipeng Wei, Peter Wilkinson
4 | Gwen Donley, Carli Lehr, Connor Swingle, Frances Wang
5 | Ryan Honomichl, JJ Huang, Xin Xin Yu, Bilal Zonjy
6 | Khaled Alayed, Kedar Mahajan, Preeti Pathak, Sarah Planchon Pope
7 | Estee Cramer, Laura Cremer, Hyun Jo Kim, Roberto Martinez
8 | Abhishek Deshpande, Jack McDonnell, Grace Park, Gabby Rieth
9 | Haimeng Bai, Sophia Cao, Kate Dobbs, Elina Misicka
10 | Vaishali (Vee) Deo, Caroline El Sanadi, Kaylee Sarna, Sandra Silva Camargo


# Quiz 1

## Quiz 1: How Long Did It Take?

```{r, echo = FALSE}
q1min <- read.csv("q1minute.csv") %>% tbl_df

ggplot(q1min, aes(x = time_on_quiz)) +
    geom_histogram(binwidth = 1, fill = "royalblue", col = "white") +
    scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10)) +
    scale_x_continuous(breaks = c(3, 6, 9, 12, 15)) + 
    labs(y = "Number of Students",
         x = "How long (in hours) did it take to do Quiz 1?") +
    geom_label(x = 11, y = 8, label = "n = 41, mean = 6.23 hours, sd = 2.69 hours") +
    geom_label(x = 11, y = 7, label = "min = 3, q25 = 4, med = 5, q75 = 7, max = 15")
```

## Is Time Taken Associated with Score?

```{r, echo = FALSE}
ggplot(q1min, aes(x = time_on_quiz, y = grade_on_quiz)) +
    geom_jitter(width = 0.2, size = 2, pch = 21, fill = "royalblue") + 
    labs(y = "(Truncated) Final Score on Quiz 1 (out of 100)",
         x = "(Jittered) How long (in hours) did it take to do Quiz 1?")
```

## Time and Grade? (with OLS and loess fits)

```{r, echo = FALSE}
ggplot(q1min, aes(x = time_on_quiz, y = grade_on_quiz)) +
    geom_smooth(method = "lm", se = FALSE, col = "red") +
    geom_smooth(method = "loess", col = "blue") +
    geom_jitter(width = 0.2, size = 2, pch = 21, fill = "royalblue") + 
    labs(y = "(Truncated) Final Score on Quiz 1 (out of 100)",
         x = "(Jittered) How long (in hours) did it take to do Quiz 1?",
         caption = "with OLS (red) and LOESS (blue) fits")
```

## OLS fit

```
Linear Regression Model
 
 ols(formula = grade_on_quiz ~ time_on_quiz, data = q1min)
 
                  Model Likelihood      Discrimination    
                     Ratio Test            Indexes        
 Obs       41     LR chi2      0.95     R2       0.023    
 sigma 7.7226     d.f.            1     R2 adj  -0.002    
 d.f.      39     Pr(> chi2) 0.3296     g        1.240    

               Coef     S.E.    t      Pr(>|t|)
 Intercept     86.8956  3.0707  28.30   <0.0001 
 time_on_quiz  -0.4333  0.4532  -0.96    0.3448  
```

## Quiz 1: What question was hardest?

Question | Votes | % of Available Points Awarded
---: | ---: | --------------:
Q21 | 14.33 | a 90%, b 88%, c 85%, d **63%**, e 66%
Q24 | 12.33 | a 76%, b 68%, c 73%, d 66%
Q19 | 8.67  | **39%**
Q23 | 1.17  | **22%**
Q01 | 1     | 90%
Q22 | 1     | 98%
Q25 | 1     | 88%
Q28 | 1     | **54%**
Q18 | 0.5   | 85%
Q15 | 0     | **59%**
Q29 | 0     | **63%**

I'll discuss Questions 15, 19, 21, 23, 24, 28 and 29 in class today.

## Scoring on the questions you thought were hardest?

```{r, echo = FALSE}
ggplot(q1min, aes(x = percent_on_hardest)) +
    geom_histogram(bins = 12, fill = "royalblue", col = "white") +
    scale_y_continuous(breaks = c(0, 3, 6, 9, 12, 15)) +
    labs(y = "Number of Students",
         x = "% of Available Points Scored on Question Deemed Hardest") +
    geom_label(x = 50, y = 12, label = "n = 41, mean = 62.3, sd = 38.5") +
    geom_label(x = 50, y = 10, label = "min = 0, q25 = 33.3, med = 75, q75 = 100, max = 100") +
    geom_label(x = 50, y = 8, label = "14/41 (34%) scored 100% on their 'hardest' question")
```

## Q21

For each row, identify the model-fitting approach that most directly leads to the specified summary.

Model-fitting options are: `ols`, `lrm`, `glm` with binomial, none of these

- `a`. C statistic
- `b`. Adjusted R^2^
- `c`. odds ratio estimate showing effect of increasing a quantitative predictor by 1 unit, while holding the others constant
- `d`. odds ratio estimate showing effect of increasing a quantitative predictor from the 25th to the 75th percentile of its distribution, while holding the others constant
- `e`. estimate of effect on a quantitative outcome associated with changing a binary predictor from 0 to 1
- `f`. Nagelkerke R-squared

## Q24

```
R-square: 0.212, Adjusted R-square: 0.204

         index.orig training   test optimism index.corrected
R-square      0.212    0.224  0.199    0.023          0.189 
``` 

Consider the model summaries above. Identify the value in the columns that matches the description for each row.

- `a`. % of variation explained using this model for the data used to fit this model
- `b`. estimate of % of variation that will be explained by this model in a new data set
- `c`. value that is plotted in a best subsets analysis
- `d`. square of correlation between observed and predicted baby weights

## Q19

Linear Regression: must include four predictors: age (in years), female (1 = female, 0 = male), severity (three categories: High, Medium, Low) and temperature (in degrees Celsius). 

Examine the Spearman rho-squared plot shown on the next slide. Suppose you are permitted to spend an additional **three** degrees of freedom. Which model? 

- `a`. `ols(outcome ~ rcs(age, 3) + temperature + rcs(severity, 3) + female %ia% age, data = data_19)`
- `b`. `ols(outcome ~ rcs(age, 4) + rcs(temperature, 3) + severity + female, data = data_19)`
- `c`. `ols(outcome ~ female*age + temperature*severity, data = data_19)`
- `d`. `ols(outcome ~ rcs(age, 3) + rcs(temperature, 5) + severity + female, data = data_19)`
- `e`. None of these models are appropriate.

## Q19 Spearman Plot

![](fig19.png)

## Q23 (beginning)

Variable | `gestation` | `mom.age` | `mom.ht` | `mom.wt` | `dad.age` | `dad.ht` | `dad.wt`
--------: | ----: | ----: |  ----: |  ----: |  ----: |  ----: |  ----: 
VIF | 1.00 | 1.63 | 1.59 | 1.58 | 1.64 | 13.578 | 13.582

A child's birth weight depends on many things, among them the parents' genetic makeup, gestation period, and mother's activities during pregnancy. Suppose we are fitting a model using the `data_23` data set (which I have provided to you, **so you should take a look at it**) to predict a child's weight at birth using seven continuous predictors: gestation period (in days), mother's age (in years), height (in inches) and (pre-pregnancy) weight (in pounds); and father's age, height and weight. We run a full model containing main effects of all predictors, and obtain the variance inflation factors shown above. 

## Q23 (actual question)

Which of the following statements best describes the most appropriate next step to take in light of this output and your examination of the `data_23` data set?

- `a`. We should calculate and examine the leverage values for our observations.
- `b`. We should draw pictures, and study the distributions of the predictors in our model.
- `c`. We should drop the `dad.wt` variable and fit a new model.
- `d`. We should drop the `dad.ht` variable and fit a new model.
- `e`. We definitely need to drop one of the predictors about the father's size, but we're not sure which one.
- `f`. We should calculate and examine the Cook's distance for our observations.
- `g`. There isn't a substantial problem here. We can confidently make predictions using this model.

## Q23 (skim)

![](fig23.png)

## Q28 and Q29

were the "best subsets" questions.

It seems that most people who got them wrong miscounted. When the plot says "# of predictors, including the intercept" then a model with x = 4 is model containing four predictors, including the intercept, or a model with intercept PLUS THREE actually interesting predictors.

## Q15

Suppose you are reviewing an academic paper and you have the four options listed below. In "How to be a Modern Scientist", Jeff Leek suggests that there is a #1 way to be a jerk reviewer. Which of the following recommendation decisions could be made by someone who was actively TRYING TO BE a jerk reviewer? (Select any that apply.)

a. Reject
b. **Major revisions**
c. **Minor revisions**
d. Accept

Leek: "The #1 way to be a jerk reviewer is ... [to ask for either major or minor revisions] ... even if you think the paper is uninteresting and you wouldn't accept it even if they did everything you said."

## General Comments on Quiz 1

I've probably said most of what should be said. 8-10 people scored within each of the following ranges:

- 90-99 (A: congratulations!)
- 87-89 (A-/B+, no problems)
- 84-86 (B+/B, near the median, no problems)
- 78-83 (a reasonable B grade, room to improve)
- below 78 (needs to improve)

If you have a complaint or question about grading on Quiz 1 after looking over the answer sketch, including the Results section, the most useful thing to do is **email it to me, or to 431-help**.

# The `crimestat` data and an OLS fit

## The `crimestat` data set

For each of 51 states (including the District of Columbia), we have the state's ID number, postal abbreviation and full name, as well as:

- **crime** - the violent crime rate per 100,000 people
- **poverty** - the official poverty rate (% of people living in poverty in the state/district) in 2014
- **single** - the percentage of households in the state/district led by a female householder with no spouse present and with her own children under 18 years living in the household in 2016
- **trump** - whether Donald Trump won the popular vote in the 2016 presidential election in that state/district (which we'll \textcolor{red}{ignore for today})

## The `crimestat` data set

```{r}
crimestat <- read.csv("crimestat.csv") %>% tbl_df
crimestat
```

## Modeling `crime` with `poverty` and `single`

Our main goal will be to build a linear regression model to predict **crime** using centered versions of both **poverty** and **single**.

```{r}
crimestat <- crimestat %>%
    mutate(pov_c = poverty - mean(poverty),
           single_c = single - mean(single))
```

## Our original (OLS) model

```{r}
(mod1 <- lm(crime ~ pov_c + single_c, data = crimestat))
```

## Significance of our coefficients?

```{r}
tidy(mod1)
```

# Robust Linear Regression with Huber Weights

## Robust Linear Regression with Huber weights

There are several ways to do robust linear regression using M-estimation, including weighting using Huber and bisquare strategies.

- Robust linear regression here will make use of a method called iteratively re-weighted least squares (IRLS) to estimate models. 
- M-estimation defines a weight function which is applied during estimation. 
- The weights depend on the residuals and the residuals depend on the weights, so an iterative process is required.

We'll fit the model, using the default weighting choice: what are called Huber weights, where observations with small residuals get a weight of 1, and the larger the residual, the smaller the weight. 

### Our robust model (using `MASS::rlm`)

```{r}
rob.huber <- rlm(crime ~ pov_c + single_c, data = crimestat)
```

## Summary of the robust (Huber weights) model

```{r}
tidy(rob.huber)
```

Now, *both* predictors appear to have estimates that exceed twice their standard error. So this is a very different result than ordinary least squares gave us.

## Glance at the robust model (vs. OLS)

```{r}
glance(mod1)
glance(rob.huber)
```

## Understanding the Huber weights a bit

Let's augment the data with results from this model, including the weights used.

```{r}
crime_with_huber <- augment(rob.huber, crimestat) %>%
    mutate(w = rob.huber$w) %>% arrange(w) %>% tbl_df

head(crime_with_huber, 3)
```

## Are cases with large residuals down-weighted?

```{r, fig.height = 4}
ggplot(crime_with_huber, aes(x = w, y = abs(.resid))) +
    geom_label(aes(label = state)) 
```

## Conclusions from the Plot of Weights

- The district of Columbia will be down-weighted the most, followed by Alaska and then Nevada and Mississppi. 
- But many of the observations will have a weight of 1. 
- In ordinary least squares, all observations would have weight 1.
- So the more cases in the robust regression that have a weight close to one, the closer the results of the OLS and robust procedures will be.

## summary(rob.huber)

```{r, echo = FALSE}
summary(rob.huber)
```

# Robust Linear Regression with the bisquare weighting function

## Robust Linear Regression with the biweight

As mentioned there are several possible weighting functions - we'll next try the biweight, also called the bisquare or Tukey's bisquare, in which all cases with a non-zero residual get down-weighted at least a little. Here is the resulting fit...

```{r}
(rob.biweight <- rlm(crime ~ pov_c + single_c,
                    data = crimestat, psi = psi.bisquare))
```

## Coefficients and Standard Errors

```{r}
tidy(rob.biweight)
```

## Understanding the biweights weights a bit

Let's augment the data, as above

```{r}
crime_with_biweights <- augment(rob.biweight, crimestat) %>%
    mutate(w = rob.biweight$w) %>% arrange(w) %>% tbl_df

head(crime_with_biweights, 3)
```

## Relationship of Weights and Residuals

```{r, fig.height = 4}
ggplot(crime_with_biweights, aes(x = w, y = abs(.resid))) +
    geom_label(aes(label = state)) 
```

## Conclusions from the biweights plot

Again, cases with large residuals (in absolute value) are down-weighted generally, but here, Alaska and Washington DC receive no weight at all in fitting the final model.

- We can see that the weight given to DC and Alaska is dramatically lower (in fact it is zero) using the bisquare weighting function than the Huber weighting function and the parameter estimates from these two different weighting methods differ. 
- The maximum weight (here, for Alabama) for any state using the biweight is still slightly smaller than 1.

## summary(rob.biweight)

```{r, echo = FALSE}
summary(rob.biweight)
```

## Comparing OLS and the two weighting schemes

```{r}
glance(mod1) # OLS
glance(rob.biweight) # biweights
glance(rob.huber) # Huber weights
```

# Bounded-Influence Regression

## Bounded-Influence Regression and Least-Trimmed Squares

Under certain circumstances, M-estimators can be vulnerable to high-leverage observations, and so, bounded-influence estimators, like least-trimmed squares (LTS) regression have been proposed. The biweight that we have discussed is often fitted as part of what is called an MM-estimation procedure, by using an LTS estimate as a starting point. 

The `ltsReg` function, which is part of the `robustbase` package (Note: **not** the `ltsreg` function from `MASS`) is what I use below to fit a least-trimmed squares model. The LTS approach minimizes the sum of the *h* smallest squared residuals, where *h* is greater than *n*/2, and by default is taken to be (*n* + *p* + 1)/2.

### Least Trimmed Squares Model

```{r}
lts1 <- ltsReg(crime ~ pov_c + single_c, data = crimestat)
```

## Summarizing the LTS model

```{r}
summary(lts1)$coeff
```

## MM estimation

Specifying the argument `method="MM"` to `rlm` requests bisquare estimates with start values determined by a preliminary bounded-influence regression, as follows...

```{r}
rob.MM <- rlm(crime ~ pov_c + single_c, 
              data = crimestat, method = "MM")

glance(rob.MM)
```

## summary(rob.MM)

```{r, echo = FALSE}
summary(rob.MM)
```

# Penalized Least Squares

## Penalized Least Squares with `rms`

We can apply a penalty to least squares directly through the `ols` function in the `rms` package. 

```{r}
d <- datadist(crimestat)
options(datadist = "d")
pls <- ols(crime ~ pov_c + single_c, penalty = 1, 
            data = crimestat, x=T, y = T)
```

## The `pls` fit

```{r, echo = FALSE}
pls
```

## How to Choose the Penalty in Penalized Least Squares?

The problem here is how to choose the penalty - and that's a subject I'll essentially skip today. The most common approach (that we've seen with the lasso) is cross-validation.

Meanwhile, what do we conclude about the fit here from AIC and BIC?

```{r}
AIC(pls); BIC(pls)
```

# Quantile Regression (on the Median)

## Quantile Regression on the Median

We can use the `rq` function in the `quantreg` package to model the **median** of our outcome (violent crime rate) on the basis of our predictors, rather than the mean, as is the case in ordinary least squares.

```{r}
rob.quan <- rq(crime ~ pov_c + single_c, data = crimestat)

glance(rob.quan)
```

## summary(rob.quan)

```{r, echo = FALSE}
summary(rob.quan <- rq(crime ~ pov_c + single_c, data = crimestat))
```

## Estimating a different quantile (tau = 0.70)

In fact, if we like, we can estimate any quantile by specifying the `tau` parameter (here `tau` = 0.5, by default, so we estimate the median.)

```{r}
(rob.quan70 <- rq(crime ~ pov_c + single_c, tau = 0.70,
                  data = crimestat))
```

# Conclusions

## Comparing Five of the Models

**Estimating the Mean**

Fit | Intercept CI | `pov_c` CI | `single_c` CI 
---------: | ----------: | ----------: | ----------:  
OLS | (`r 364.4 - 2*22.9`, `r 364.4 + 2*22.9`) | (`r 16.11 - 2*9.62`, `r 16.11 + 2*9.62`) | (`r 23.84 - 2*18.38`, `r decim(23.84 + 2*18.38,2)`) 
Robust (Huber) | (`r decim(343.8 - 2*11.9,1)`, `r 343.8 + 2*11.9`) | (`r 11.91 - 2*5.51`, `r 11.91 + 2*5.51`) | (`r 30.99 - 2*10.53`, `r 30.99 + 2*10.53`) 
Robust (biweight) | (`r 336.1 - 2*12.7`, `r 336.1 + 2*12.7`) | (`r decim(10.32 - 2*5.31,2)`, `r 10.32 + 2*5.31`) | (`r 34.71 - 2*10.16`, `r 34.71 + 2*10.16`) 
Robust (MM) | (`r decim(336.4 - 2*13.2,1)`, `r 336.4 + 2*13.2`) | (`r decim(10.56 - 2*5.53,2)`, `r 10.56 + 2*5.53`) | (`r 32.78 - 2*10.58`, `r 32.78 + 2*10.58`) 

**Note**: CIs estimated for OLS and Robust methods as point estimate $\pm$ 2 standard errors

**Estimating the Median**

Fit | Intercept CI | `pov_c` CI | `single_c` CI | AIC | BIC
-----------------: | ----------: | ----------: | ----------: 
Quantile (Median) Reg | (336.9, 366.2) | (3.07, 28.96) | (4.46, 48,19) 

## Comparing AIC and BIC


Fit | AIC | BIC
---------: | ----------: | ----------: 
OLS | `r decim(AIC(mod1), 1)` | `r decim(BIC(mod1), 1)`
Robust (Huber) | `r decim(AIC(rob.huber), 1)` | `r decim(glance(rob.huber)$BIC[1], 1)`
Robust (biweight) | `r decim(AIC(rob.biweight), 1)` | `r decim(glance(rob.biweight)$BIC[1], 1)`
Robust (MM) | `r decim(AIC(rob.MM), 1)` | `r decim(glance(rob.MM)$BIC[1], 1)`
Quantile (median) | `r decim(AIC(rob.quan), 1)` | `r decim(glance(rob.quan)$BIC[1], 1)`


## Some General Thoughts

1. When comparing the results of a regular OLS regression and a robust regression for a data set which displays outliers, if the results are very different, you will most likely want to use the results from the robust regression. 
    - Large differences suggest that the model parameters are being highly influenced by outliers. 
2. Different weighting functions have advantages and drawbacks. 
    - Huber weights can have difficulties with really severe outliers.
    - Bisquare weights can have difficulties converging or may yield multiple solutions. 
    - Quantile regression approaches have some nice properties, but describe medians (or other quantiles) rather than means.

## Project 1 Groups for Discussion in Class on Thursday

Group | Names
------: | -----------------------------------------------------------------------------
1 | Laura Baldassari, Jenny Feng, Maher Kazimi, Satyakam Mishra, Vinh Trinh
2 | Zainab (Albar) Albar, Dongze (Zaza) He, Nik Krieger, Andrew Shan
3 | Andrew Tang, Sneha Vakamudi, Ruipeng Wei, Peter Wilkinson
4 | Gwen Donley, Carli Lehr, Connor Swingle, Frances Wang
5 | Ryan Honomichl, JJ Huang, Xin Xin Yu, Bilal Zonjy
6 | Khaled Alayed, Kedar Mahajan, Preeti Pathak, Sarah Planchon Pope
7 | Estee Cramer, Laura Cremer, Hyun Jo Kim, Roberto Martinez
8 | Abhishek Deshpande, Jack McDonnell, Grace Park, Gabby Rieth
9 | Haimeng Bai, Sophia Cao, Kate Dobbs, Elina Misicka
10 | Vaishali (Vee) Deo, Caroline El Sanadi, Kaylee Sarna, Sandra Silva Camargo
