---
title: "432 Class 11 Slides"
author: "github.com/THOMASELOVE/432-2018"
date: "2018-02-20"
output:
  beamer_presentation:
    theme: "Madrid"
    colortheme: "lily"
    fonttheme: "structurebold"
    fig_caption: FALSE
---

```{r set-options, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(comment=NA)
options(width = 60)
```

## Setup

```{r, warning = FALSE, message = FALSE}
library(skimr)
library(pROC)
library(ROCR)
library(rms) # note: also loads Hmisc
library(simputation)
library(broom)
library(tidyverse)
```

## Today's Materials

- Logistic Regression and the Framingham Study (part 2)
- Performing Linear Regression with `ols`
- Hormone Therapy and Baseline LDL in the `HERS` trial 

The HERS trial is described in Vittinghoff et al., especially Chapter 4.

# Logistic Regression and Framingham

## Data Ingest, Cleanup (from Class 10)

```{r}
fram <- read.csv("data/fram_new.csv") %>% tbl_df
set.seed(432001)
fram1 <- fram %>%
    impute_pmm(educ + cigs_day + heart_r ~ age + smoker) %>%
    impute_rlm(bmi + tot_chol ~ sex + age + sbp + heart_r) %>%
    impute_pmm(bp_meds ~ hx_htn + bmi + tot_chol) %>%
    impute_rlm(glucose ~ hx_dm + bmi + tot_chol + age) %>%
    mutate(ed_f = fct_recode(factor(educ),
                   "1_Some_HS" = "1", "2_HS_grad" = "2",
                   "3_Some_Col" = "3", "4_Col_grad" = "4"))
fram2 <- fram1 %>%
    select(subj, sex, age, smoker, cigs_day, bp_meds,
           hx_stroke, hx_htn, hx_dm, ed_f, tot_chol,
           sbp, dbp, bmi, heart_r, glucose, CHD_10)
```

## The Models We've Fit (predicting `CHD_10`)

```{r}
m_01 <- glm(CHD_10 ~ hx_htn, data = fram2, 
            family = binomial)

d <- datadist(fram2)
options(datadist = "d")
m_01_lrm <- lrm(CHD_10 ~ hx_htn, data = fram2, x = T, y = T)

m_02 <- glm(CHD_10 ~ hx_htn + tot_chol, 
            data = fram2, family = binomial)
m_02_lrm <- lrm(CHD_10 ~ hx_htn + tot_chol, data = fram2,
                x = TRUE, y = TRUE)
```

## Assessing Predictive Quality: Discrimination

Key measures: C statistic, Nagelkerke R^2^

Model | C statistic | Nagelkerke R^2^
----------: | ------: | -------:
`m_01_lrm` | 0.614 | 0.051
`m_02_lrm` | 0.640 | 0.055

and we could use `validate(model)` to address how well these results might hold up in new data.

## Assessing Predictive Quality: Calibration Curves

```{r, eval = FALSE}
plot(calibrate(m_01_lrm), main = "Calibration for m_01_lrm")
plot(calibrate(m_02_lrm), main = "Calibration for m_02_lrm")
```

![](figures/figX.png)

## Assessing Predictive Quality: Goodness of Fit Test

This uses the le Cessie-van Houwelingen-Copas-Hosmer unweighted sum of squares test statistic. to produce (using up just one degree of freedom) a global goodness of fit test. It's available through `residuals` applied to a `lrm` fit, with `type = "gof"`). 

The essential components of a logistic regression fit are:

1. The logit transformation is the correct function linking the covariates with the conditional mean,
2. The linear predictor is correct (we don't need to include additional variables, transformations of predictors or interaction terms), and
3. The variance follows a Bernoulli distribution.

See [\textcolor{blue}{Hosmer et al. 1997}](http://stat.duke.edu/~zo2/dropbox/goflogistic.pdf)

## The Omnibus Goodness of Fit Test

As in any omnibus test, a significant result here is difficult to interpret, but it means that something somewhere in the model is probably wrong. 

- [\textcolor{blue}{Harrell}](http://r.789695.n4.nabble.com/Q-Goodness-of-fit-test-of-a-logistic-regression-model-using-rms-package-td2403618.html): I focus on directed tests such as allowing all continuous variables to have nonlinear effects or allowing selected interactions, and finding out how important the complex model terms are. 

```{r, eval = FALSE}
round(residuals(m_01_lrm, type = "gof"),3)
round(residuals(m_02_lrm, type = "gof"),3)
```

```
       Sum of squared   Expected
           errors       value|H0      SD          Z      P 
Model 1   528.985        528.985   0.000  -2268.981  0.000 
Model 2   527.948        527.291   0.331      1.986  0.047
```

Looking better in `m_02_lrm` but still some work to do. 

# Goal 3. Kitchen Sink Model for `CHD_10`

## Focus on model with `lrm` first!

```{r}
m_03 <- glm(CHD_10 ~ hx_htn + tot_chol + sex + age +
                    smoker + cigs_day + bp_meds + 
                    hx_stroke + hx_dm + ed_f + sbp + dbp +
                    bmi + heart_r + glucose, 
                data = fram2, family = binomial)

d <- datadist(fram2)
options(datadist = "d")
m_03_lrm <- lrm(CHD_10 ~ hx_htn + tot_chol + sex + age +
                    smoker + cigs_day + bp_meds + 
                    hx_stroke + hx_dm + ed_f + sbp + dbp +
                    bmi + heart_r + glucose, 
                data = fram2, x = TRUE, y = TRUE)
```

## `m_03_lrm` (first section of output)

![](figures/figF_07.png)

## `m_03_lrm` (second section of output)

![](figures/figF_08.png)

## Validating our Summary Statistics

```{r}
set.seed(432020) # probably better to set a seed
validate(m_03_lrm)[1:4,] # to fit things in the slide
```

## `plot(summary(m_03_lrm))`

```{r, echo = FALSE}
plot(summary(m_03_lrm))
```

## `plot(anova(m_03_lrm))`

```{r, echo = FALSE}
plot(anova(m_03_lrm))
```

## Can we see the prediction results?

```{r}
ggplot(Predict(m_03_lrm), 
       anova = anova(m_03_lrm), pval = TRUE)
```

## What about on a better scale?

```{r}
ggplot(Predict(m_03_lrm, fun = plogis))
```

## Calibration of `mod_03_lrm`

```{r}
set.seed(432029); plot(calibrate(m_03_lrm))
```

## Goodness of fit test?

```{r}
round(residuals(m_03_lrm, type = "gof"),3)
```

## Nomogram of `mod_03_lrm`

```{r}
plot(nomogram(m_03_lrm, fun = plogis))
```

## Comparing our Three Nested Models

```{r}
anova(m_01, m_02, m_03)
```

## Model 2 vs. Model 3 at a glance

```{r}
glance(m_02)
glance(m_03)
```

